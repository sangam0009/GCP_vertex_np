{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cdad542-6470-4afe-8fe1-f502d2e1d0de",
   "metadata": {},
   "source": [
    "# House Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4e8639-3f6f-41bb-803b-93af2790475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import google.cloud.aiplatform as aip\n",
    "from google.cloud import storage\n",
    "import gcsfs\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Artifact,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Model,\n",
    "                        Output,\n",
    "                        Metrics,\n",
    "                        ClassificationMetrics,\n",
    "                        component, \n",
    "                        Markdown)\n",
    "\n",
    "from kfp.v2 import compiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52413f7f-abe2-43b9-b6a9-183a304dddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_URI = 'gs://mle-gcp-kfp-v1'\n",
    "PIPELINE_ROOT = \"{}/pipeline_root/house_price\".format(BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c337c0ca-e93f-4338-8aa7-c3cb9c0a1cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"tiger-mle\"\n",
    "REGION = \"us-east1\"\n",
    "ZONE = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "422bbf8a-f72a-4f2a-9cde-4d73068bf004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "! gcloud config set project $PROJECT_ID\n",
    "! gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d258a169-0fdd-4a19-af91-7921c67f098a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Credentialed Accounts\n",
      "ACTIVE  ACCOUNT\n",
      "*       378786916136-compute@developer.gserviceaccount.com\n",
      "\n",
      "To set the active account, run:\n",
      "    $ gcloud config set account `ACCOUNT`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c6d1ae4-a9dd-4a46-96ec-97079bc97858",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'tiger-mle'\n",
    "file_uri = 'gs://vertex-ai-bucket-house-price-pred/data_base/housing.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24117d36-219a-43b2-bb7f-dbfa10b39530",
   "metadata": {},
   "source": [
    "### Reading data from GCP Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1041ce6a-1579-4b52-be21-496c55348ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(packages_to_install=['gcsfs==2022.02.0','pandas==1.1.4','scikit-learn==1.0.1'])\n",
    "def get_data(project_id: str,file_uri: str,house_dataset: Output[Dataset]):\n",
    "    import gcsfs\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    \n",
    "    fs = gcsfs.GCSFileSystem()\n",
    "    f = fs.open(file_uri)\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    \"\"\"train, test = tts(df, test_size=0.3)\n",
    "    \n",
    "    train.to_csv(dataset_train.path)\n",
    "    test.to_csv(dataset_test.path)\"\"\"\n",
    "    \n",
    "    df.to_csv(house_dataset.path)\n",
    "    #return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a828e3-5841-48d9-95b2-c853ec6cf092",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "227bb545-56fd-4d4b-a58f-2e789609b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(  packages_to_install = [\n",
    "        \"pandas==1.3.4\",\n",
    "        \"xgboost==1.5.1\",\n",
    "        \"scikit-learn==1.0.1\",\n",
    "        \"numpy\"\n",
    "    ],\n",
    ")\n",
    "def preprocess(\n",
    "        dataset: Input[Dataset],\n",
    "        dataset_train: Output[Dataset],\n",
    "        dataset_test: Output[Dataset]):\n",
    "    import pandas as pd\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    import numpy as np\n",
    "    \n",
    "    housing = pd.read_csv(dataset.path)\n",
    "    print('ok')\n",
    "    \n",
    "    #train_set, test_set = tts(data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    \n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "    housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "    \n",
    "    housing_num[\"income_cat\"] = pd.cut(\n",
    "        housing_num[\"median_income\"],\n",
    "        bins=[0.0, 1.5, 3.0, 4.5, 6.0, np.inf],\n",
    "        labels=[1, 2, 3, 4, 5]\n",
    "    )\n",
    "    \n",
    "    imputer.fit(housing_num)\n",
    "    X = imputer.transform(housing_num)\n",
    "    housing_tr = pd.DataFrame(X, index=housing_num.sort_index().index,columns=housing_num.columns)\n",
    "\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(housing_tr, housing_tr[\"income_cat\"]):\n",
    "        strat_train_set = housing_tr.loc[train_index]\n",
    "        strat_test_set = housing_tr.loc[test_index]\n",
    "        \n",
    "    strat_train_set.to_csv(dataset_train.path)\n",
    "    strat_test_set.to_csv(dataset_test.path)\n",
    "    print(strat_train_set.columns,strat_train_set.shape)\n",
    "    print(strat_test_set.columns,strat_test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ee52d4-5554-4bef-8e26-f4ad02050e99",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09479df6-1f20-4e75-9c68-f3141b4d4368",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"scikit-learn==1.0.1\",\"pandas\",\"xgboost==1.5.1\",\"joblib\",\"google.cloud\"])\n",
    "def train_model(\n",
    "    dataset_train: Input[Dataset],\n",
    "    model_artifact: Output[Model],\n",
    "    model: Output[Model]\n",
    "    \n",
    "):\n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from xgboost import XGBRegressor\n",
    "    import pandas as pd\n",
    "    import joblib\n",
    "    from google.cloud import storage\n",
    "    import os\n",
    "    \n",
    "    housing_train = pd.read_csv(dataset_train.path)\n",
    "    \n",
    "    housing_prepared = housing_train.drop(columns=['median_house_value']).values\n",
    "    print(\"housing_prepared\",housing_prepared)\n",
    "    housing_labels = housing_train[\"median_house_value\"].copy()\n",
    "    print(\"housing_labels\",housing_labels)\n",
    "    #print('ok')\n",
    "    \n",
    "    #lin_reg = LinearRegression()\n",
    "    xgmodel = XGBRegressor()\n",
    "    print('start--')\n",
    "    xgmodel.fit(housing_prepared,housing_labels)\n",
    "    print('fit--')\n",
    "    score = xgmodel.score(\n",
    "        housing_prepared,\n",
    "        housing_labels\n",
    "    )\n",
    "    print('save--')\n",
    "    \n",
    "    model_artifact.metadata[\"train_score\"] = float(score)\n",
    "    model_artifact.metadata[\"framework\"] = \"xgboost\"\n",
    "\n",
    "    print(model_artifact.path)\n",
    "    \n",
    "    xgmodel.save_model(model_artifact.path)\n",
    "    #model.save(model.path)\n",
    "    \n",
    "    #save model\n",
    "    print(\"Dump\")\n",
    "    filename = \"house_model.joblib\"\n",
    "    joblib.dump(xgmodel,filename)\n",
    "    \n",
    "    print(model_artifact.path)\n",
    "    print(model.path)\n",
    "    \n",
    "    print(\"gcp save\")\n",
    "    print(filename,type(filename))\n",
    "    \n",
    "    bucket = storage.Client().bucket('mle-gcp-kfp-v1')\n",
    "    #des_bob = 'models'\n",
    "    path = model.path\n",
    "    path = path.replace('/gcs/mle-gcp-kfp-v1/','')\n",
    "    #path = path.replace('model_save_gcp','')\n",
    "    print('path--',path)\n",
    "    blob = bucket.blob(path+str('.joblib'))\n",
    "    print('blob--',blob)\n",
    "    blob.upload_from_filename(filename)\n",
    "    \"\"\"\n",
    "    #lient = storage.Client()\n",
    "    #bucket = client.get_bucket('mle-gcp-tbk-1')\n",
    "    bucket = storage.Client().bucket('gs://mle-gcp-kfp-v1')\n",
    "    #ucket = client.get_bucket(model.path)\n",
    "    #blob = bucket.blob('model')\n",
    "    path = model_save_gcp.path\n",
    "    path = path.replace('/gcs/mle-gcp-kfp-v1/','/')\n",
    "    path = path.replace('model_save_gcp','')\n",
    "    print(path)\n",
    "    print('saving')\n",
    "    #blob = bucket.blob('{}/{}'.format(path,filename))\n",
    "    #blob = bucket.blob('{}'.format(path))\n",
    "    #blob = blob.replace(', /','/')\n",
    "    print(blob)\n",
    "    blob.upload_from_filename(filename) \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    model_directory = os.environ[model_save_gcp.path]\n",
    "    print('1')\n",
    "    storage_path = os.path.join(model_directory, filename)\n",
    "    print('2')\n",
    "    blob = storage.blob.Blob.from_string(storage_path, client=storage.Client())\n",
    "    print('1')\n",
    "    blob.upload_from_filename(filename) \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # Upload model artifact to Cloud Storage\n",
    "    model_directory = os.environ['AIP_MODEL_DIR']\n",
    "    storage_path = os.path.join(model_directory, artifact_filename)\n",
    "    blob = storage.blob.Blob.from_string(storage_path, client=storage.Client())\n",
    "    blob.upload_from_filename(local_path)\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f13379b8-8e98-4ab3-ab90-0f3b6e1e0b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87a075-46a7-4130-b9bb-96af0d43dd57",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69acf674-9384-4669-b832-e36a7ddb4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install = [\n",
    "        \"pandas==1.3.4\",\n",
    "        \"scikit-learn==1.0.1\",\n",
    "        \"xgboost==1.5.1\"\n",
    "    ],\n",
    ")\n",
    "def eval_model(\n",
    "    test_set: Input[Dataset],\n",
    "    xgb_model: Input[Model],\n",
    "    metrics: Output[ClassificationMetrics],\n",
    "    smetrics: Output[Metrics]\n",
    ") -> NamedTuple(\"Outputs\", [(\"deploy\", str)]): \n",
    "    from xgboost import XGBRegressor\n",
    "    import pandas as pd\n",
    "    \n",
    "    data = pd.read_csv(test_set.path)\n",
    "    model = XGBRegressor()\n",
    "    model.load_model(xgb_model.path)\n",
    "    \n",
    "    \n",
    "    housing_prepared = data.drop(columns=['median_house_value']).values\n",
    "    housing_labels = data[\"median_house_value\"].copy()\n",
    "    \n",
    "    score = model.score(\n",
    "        housing_prepared,\n",
    "        housing_labels,\n",
    "    )\n",
    "    \n",
    "    xgb_model.metadata[\"test_score\"] = float(score)\n",
    "\n",
    "    deploy = \"true\"\n",
    "    #compare threshold or to previous\n",
    "\n",
    "    return (deploy,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d4526d-b056-4938-9d41-bc110099b351",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92b642e6-209d-4e8f-8b4b-de87caf48553",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install=[\"google-cloud-aiplatform==1.3.0\"])\n",
    "def deploying(\n",
    "    model: Input[Model],\n",
    "    project: str,\n",
    "    region: str,):\n",
    "  \n",
    "    import logging\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project=project, location=region)\n",
    "    \n",
    "    \n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "    logging.debug(model)\n",
    "\n",
    "    print('model--',model)\n",
    "\n",
    "    import os\n",
    "    path,file = os.path.split(model.uri)\n",
    "\n",
    "    import datetime\n",
    "\n",
    "      # datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "      # serving image https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers#xgboost\n",
    "    deployed_model = aiplatform.Model.upload(\n",
    "           display_name=\"xgboost-pipeline-1\",\n",
    "           artifact_uri = path,\n",
    "           serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-4:latest\"\n",
    "      ) \n",
    "\n",
    "    \"\"\"\n",
    "    #end point\n",
    "    print('create end point')\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name='xgboost-pipeline-1', project=project, location=region,\n",
    "    )\n",
    "    print('ep name',endpoint.display_name)\n",
    "    print('ep rname',endpoint.resource_name)\n",
    "    \n",
    "    print('Deploy model')\n",
    "    deploy_model = aiplatform.Model(model_name='xgboost-pipeline-1')\n",
    "    \n",
    "    deply_model.deploy(\n",
    "        endpoint = endpoint,\n",
    "        deployed_model_display_name = \"xgboost-pipeline-1\",\n",
    "        machine_type= \"n1-standard-2\",\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1,\n",
    "        sync = True,\n",
    "    )\n",
    "    \n",
    "    deployed_model.wait()\n",
    "    \n",
    "    print('dm name--',deployed_model.display_name)\n",
    "    print('dm rname--',deployed_model.resource_name)\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a68335-8832-4038-b99f-94743a13fc91",
   "metadata": {},
   "source": [
    "### Building a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2185b01-6563-46b8-ba3e-e7eca39f262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"house-price-pred\",\n",
    "    description=\"House prediction\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "def pipeline(project_id: str = 'tiger-mle',\n",
    "                 file_uri: str = 'gs://vertex-ai-bucket-house-price-pred/data_base/housing.csv'):\n",
    "    get_data_op = get_data(project_id,file_uri)\n",
    "    pipe_preprocess = preprocess(get_data_op.outputs['house_dataset'])\n",
    "    pipe_train_model = train_model(pipe_preprocess.outputs['dataset_train'])\n",
    "    eval_op = eval_model(\n",
    "        pipe_preprocess.outputs['dataset_test'],\n",
    "        xgb_model=pipe_train_model.outputs[\"model_artifact\"]\n",
    "    )\n",
    "    deploy_op = deploying(pipe_train_model.outputs[\"model_artifact\"], \n",
    "                         \"tiger-mle\",\n",
    "                         \"us-east1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e598f5ea-8755-4389-a863-c6c255922ba4",
   "metadata": {},
   "source": [
    "### Complie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c459a02-75a9-4453-b105-24712ae9700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler  # noqa: F811\n",
    "\n",
    "compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"house_pipeline.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d83b5c62-8eb6-4f1f-b770-ac8ae9b1e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddee691-c483-4aaf-8289-4769150b099f",
   "metadata": {},
   "source": [
    "### Run the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec041503-a582-471e-a5b1-419164ca4a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/378786916136/locations/us-central1/pipelineJobs/house-price-pred-20220517130001\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/378786916136/locations/us-central1/pipelineJobs/house-price-pred-20220517130001')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/house-price-pred-20220517130001?project=378786916136\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/378786916136/locations/us-central1/pipelineJobs/house-price-pred-20220517130001 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/378786916136/locations/us-central1/pipelineJobs/house-price-pred-20220517130001 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/378786916136/locations/us-central1/pipelineJobs/house-price-pred-20220517130001 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob run completed. Resource name: projects/378786916136/locations/us-central1/pipelineJobs/house-price-pred-20220517130001\n"
     ]
    }
   ],
   "source": [
    "DISPLAY_NAME = \"intro_\" + TIMESTAMP\n",
    "\n",
    "job = aip.PipelineJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    template_path=\"house_pipeline.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b55254-30b2-4320-b298-da0afe9c6f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
